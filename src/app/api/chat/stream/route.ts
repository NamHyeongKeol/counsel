import { NextRequest } from "next/server";
import { GoogleGenerativeAI } from "@google/generative-ai";
import { prisma } from "@/lib/db";
import { AIModelId, calculateCost } from "@/lib/ai/constants";
import { streamChat } from "@/lib/ai/provider";
import {
    DEFAULT_SYSTEM_PROMPT,
    DEFAULT_INTIMACY_MODIFIERS,
    PROMPT_KEYS
} from "@/lib/prompts/defaults";

interface Message {
    role: "user" | "assistant";
    content: string;
}

// DBì—ì„œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¡°íšŒ
async function getSystemPromptFromDB(intimacyLevel: number = 1): Promise<string> {
    try {
        const systemPrompt = await prisma.prompt.findFirst({
            where: {
                key: PROMPT_KEYS.SYSTEM,
                isActive: true,
                intimacyLevel: null,
                locale: "ko",
            },
        });

        const intimacyModifier = await prisma.prompt.findFirst({
            where: {
                key: PROMPT_KEYS.INTIMACY_MODIFIER,
                isActive: true,
                intimacyLevel,
                locale: "ko",
            },
        });

        const basePrompt = systemPrompt?.content || DEFAULT_SYSTEM_PROMPT;
        const modifier = intimacyModifier?.content || DEFAULT_INTIMACY_MODIFIERS[intimacyLevel] || "";

        return `${basePrompt}\n\n${modifier}`;
    } catch (error) {
        console.error("DB í”„ë¡¬í”„íŠ¸ ì¡°íšŒ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©:", error);
        return `${DEFAULT_SYSTEM_PROMPT}\n\n${DEFAULT_INTIMACY_MODIFIERS[intimacyLevel] || ""}`;
    }
}

export async function POST(request: NextRequest) {
    try {
        const body = await request.json();
        const { conversationId, content } = body;

        if (!conversationId || !content) {
            return new Response(JSON.stringify({ error: "Missing required fields" }), {
                status: 400,
                headers: { "Content-Type": "application/json" },
            });
        }

        // ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
        const userMessage = await prisma.message.create({
            data: {
                conversationId,
                role: "user",
                content,
            },
        });

        // ì´ì „ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ
        const previousMessages = await prisma.message.findMany({
            where: {
                conversationId,
                isDeleted: false,
            },
            orderBy: { createdAt: "asc" },
        });

        // ì²« ë©”ì‹œì§€ê°€ modelì´ë©´ ë”ë¯¸ user ë©”ì‹œì§€ ì¶”ê°€
        let adjustedMessages: Message[] = previousMessages.map((m) => ({
            role: m.role as "user" | "assistant",
            content: m.content,
        }));

        if (adjustedMessages.length > 0 && adjustedMessages[0].role === "assistant") {
            adjustedMessages = [
                { role: "user" as const, content: "ì•ˆë…•í•˜ì„¸ìš”" },
                ...adjustedMessages
            ];
        }

        // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¡°íšŒ (ì¸íŠ¸ë¡œ ë©”ì‹œì§€ ì¹œë°€ë„ëŠ” ê¸°ë³¸ 1)
        const systemPrompt = await getSystemPromptFromDB(1);

        // ëŒ€í™”ë°© ì •ë³´ ì¡°íšŒ (ëª¨ë¸ ì„¤ì •ì„ ìœ„í•´)
        const conversation = await prisma.conversation.findUnique({
            where: { id: conversationId },
            select: { model: true }
        });

        const modelId = (conversation?.model as AIModelId) || "gemini-3-flash-preview";

        // ì „ì²´ ì‘ë‹µ ìˆ˜ì§‘ (DB ì €ì¥ìš©)
        let fullResponse = "";
        let finalMetadata = { inputTokens: null as number | null, outputTokens: null as number | null };

        // ReadableStream ìƒì„±
        const stream = new ReadableStream({
            async start(controller) {
                const encoder = new TextEncoder();

                try {
                    // userMessage ID ë¨¼ì € ì „ì†¡
                    controller.enqueue(encoder.encode(`data: ${JSON.stringify({
                        type: "userMessage",
                        id: userMessage.id,
                        content: userMessage.content,
                        createdAt: userMessage.createdAt,
                    })}\n\n`));

                    // AI Provider ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ
                    await streamChat(
                        {
                            messages: adjustedMessages,
                            modelId,
                        },
                        {
                            onChunk: (text) => {
                                fullResponse += text;
                                controller.enqueue(encoder.encode(`data: ${JSON.stringify({
                                    type: "chunk",
                                    content: text
                                })}\n\n`));
                            },
                            onDone: async (text, metadata) => {
                                finalMetadata = metadata;

                                // ë¹„ìš© ê³„ì‚°
                                const cost = calculateCost(modelId, metadata.inputTokens, metadata.outputTokens);

                                // ì‘ë‹µ ì™„ë£Œ í›„ DBì— ì €ì¥
                                const assistantMessage = await prisma.message.create({
                                    data: {
                                        conversationId,
                                        role: "assistant",
                                        content: text,
                                        model: modelId,
                                        inputTokens: metadata.inputTokens,
                                        outputTokens: metadata.outputTokens,
                                        cost: cost,
                                    },
                                });

                                // ëŒ€í™” ì œëª© ì—…ë°ì´íŠ¸ (ì²« ë©”ì‹œì§€ì¸ ê²½ìš°)
                                if (previousMessages.length === 1) {
                                    await prisma.conversation.update({
                                        where: { id: conversationId },
                                        data: {
                                            title: content.slice(0, 50) + (content.length > 50 ? "..." : ""),
                                        },
                                    });
                                }

                                // ì™„ë£Œ ë©”ì‹œì§€ ì „ì†¡
                                controller.enqueue(encoder.encode(`data: ${JSON.stringify({
                                    type: "done",
                                    assistantMessageId: assistantMessage.id,
                                    createdAt: assistantMessage.createdAt,
                                    model: modelId,
                                    inputTokens: metadata.inputTokens,
                                    outputTokens: metadata.outputTokens,
                                    cost,
                                })}\n\n`));

                                controller.close();
                            },
                            onError: (error) => {
                                throw error;
                            }
                        }
                    );
                } catch (error) {
                    console.error("ìŠ¤íŠ¸ë¦¬ë° ì—ëŸ¬:", error);

                    // ì—ëŸ¬ ì‹œì—ë„ DBì— ì €ì¥
                    const errorMessage = "ì£„ì†¡í•´ìš”, ì ì‹œ ë¬¸ì œê°€ ìƒê²¼ì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”! ğŸ˜¢";
                    const assistantMessage = await prisma.message.create({
                        data: {
                            conversationId,
                            role: "assistant",
                            content: errorMessage,
                            model: modelId,
                        },
                    });

                    controller.enqueue(encoder.encode(`data: ${JSON.stringify({
                        type: "error",
                        content: errorMessage,
                        assistantMessageId: assistantMessage.id,
                    })}\n\n`));
                    controller.close();
                }
            },
        });

        return new Response(stream, {
            headers: {
                "Content-Type": "text/event-stream",
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
            },
        });
    } catch (error) {
        console.error("API ì—ëŸ¬:", error);
        return new Response(JSON.stringify({ error: "Internal server error" }), {
            status: 500,
            headers: { "Content-Type": "application/json" },
        });
    }
}
